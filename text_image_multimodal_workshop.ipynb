{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "744c29cd",
   "metadata": {},
   "source": [
    "# Text and images: Getting Started with Multimodal on Sagemaker\n",
    "Information in the real world usually comes as different sensory input/output channels, like: images that can be associated with text explanations; or text that contains images to more clearly express the main idea of the article. \n",
    "*Multimodal learning* is a good model to represent the joint representations of different modalities.\n",
    "In this talk  we would provide a gentle introduction to Multimodal learning and would train and deploy a multimodal predictor based on natural language text, images and tabular data using SageMaker and AutoGloun.\n",
    "\n",
    "We will train a model that takes pet NLP descriptions, images and tabular features to predict how fast (category) they will get adopted.\n",
    "![petfinderlogo](./img/dataset_example.png)\n",
    "\n",
    "<sup>This example is developed based on the AutoMM multimodal example [here](https://auto.gluon.ai/dev/tutorials/multimodal/beginner_multimodal.html).</sup>\n",
    "\n",
    "## Dataset\n",
    "For demonstration, we use a simplified and subsampled version of [PetFinder dataset](https://www.kaggle.com/c/petfinder-adoption-prediction). The task is to predict the animals’ adoption rates based on their adoption profile information. In this simplified version, the adoption speed is grouped into two categories: 0 (slow) and 1 (fast).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8de9d7f",
   "metadata": {},
   "source": [
    "## Step 1: Install libraries and prepare environment \n",
    "> ⚠ **Important: this workshop was tested on ml.g4dn.8xlarge, 200 GB (!!!), conda_mxnet_p37 kernel** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04116606",
   "metadata": {},
   "source": [
    "Because 'llvmlite' is a distutils installed project, pip is not able to remove it. \n",
    "Let's remove it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2fc44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "!find /home/ec2-user/anaconda3 -type f -name '*llvmlite*.egg-info' -delete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67add2ec",
   "metadata": {},
   "source": [
    "Next, we'll upgrade pip amd install autogluon lib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a65446",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install -U pip\n",
    "%pip install -U setuptools wheel\n",
    "%pip install -U mxnet<2.0.0\n",
    "%pip install autogluon --ignore-installed\n",
    "%pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4235ea7",
   "metadata": {},
   "source": [
    "To ensure we can run local mode, increase the conda memory to 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e17ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -f image.py /home/ec2-user/anaconda3/envs/mxnet_p37/lib/python3.7/site-packages/sagemaker/local/image.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841a5012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only run the below cells when you are using sagemaker notebook instances\n",
    "!bash ./prepare-docker.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12198ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://raw.githubusercontent.com/aws-samples/amazon-sagemaker-script-mode/master/local_mode_setup.sh\n",
    "!/bin/bash ./local_mode_setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ae9e11",
   "metadata": {},
   "source": [
    "Restart the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7429ae57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.Application.instance().kernel.do_shutdown(True) #automatically restarts kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060403db",
   "metadata": {},
   "source": [
    "## Step 2: Download and explore data\n",
    "\n",
    "In this section, we will firstly download the petFinder dataset and explore the data to understand what the dataset consists of. Please wait until the kernel is ready before executing the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0587f001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary python packages\n",
    "\n",
    "import sagemaker\n",
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from sagemaker.mxnet import MXNet\n",
    "from autogluon.core.utils.loaders import load_zip\n",
    "from sagemaker.s3 import S3Uploader, S3Downloader, s3_path_join\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sklearn import metrics\n",
    "from IPython.display import Image, display\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/DEMO-autogluon-text-image-multimodel\"\n",
    "region = sagemaker_session.boto_region_name\n",
    "account_id = sagemaker_session.account_id()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9336031",
   "metadata": {},
   "source": [
    "To get started, let’s download and prepare the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b934e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dir = './ag_automm_tutorial'\n",
    "zip_file = 'https://automl-mm-bench.s3.amazonaws.com/petfinder_for_tutorial.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ab642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "load_zip.unzip(zip_file, unzip_dir=download_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57331e35",
   "metadata": {},
   "source": [
    "Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380710e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = download_dir + '/petfinder_for_tutorial'\n",
    "train_data = pd.read_csv(f'{dataset_path}/train.csv', index_col=0)\n",
    "test_data = pd.read_csv(f'{dataset_path}/test.csv', index_col=0)\n",
    "label_col = 'AdoptionSpeed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fe8c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand the image paths to load them in training.\n",
    "image_col = 'Images'\n",
    "train_data[image_col] = train_data[image_col].apply(lambda ele: ele.split(';')[0]) # Use the first image for a quick tutorial\n",
    "test_data[image_col] = test_data[image_col].apply(lambda ele: ele.split(';')[0])\n",
    "\n",
    "\n",
    "def path_expander(path, base_folder):\n",
    "    path_l = path.split(';')\n",
    "    return ';'.join([os.path.abspath(os.path.join(base_folder, path)) for path in path_l])\n",
    "\n",
    "train_data[image_col] = train_data[image_col].apply(lambda ele: path_expander(ele, base_folder=dataset_path))\n",
    "test_data[image_col] = test_data[image_col].apply(lambda ele: path_expander(ele, base_folder=dataset_path))\n",
    "\n",
    "train_data[image_col].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bfcc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['AdoptionSpeed'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1823e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.hist(figsize=(20,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71372b3",
   "metadata": {},
   "source": [
    "Each animal’s adoption profile includes pictures, a text description, and various tabular features such as age, breed, name, color, and more. Let’s look at an example row of data and display the text description and a picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146d0bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_row = train_data.iloc[0]\n",
    "\n",
    "example_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9b9304",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_row['Description']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c076c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image = example_row[image_col]\n",
    "\n",
    "pil_img = Image(filename=example_image)\n",
    "display(pil_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2fef1d",
   "metadata": {},
   "source": [
    "To use the data for model training using SageMaker trainingjob, we will upload the data to s3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e280be",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_data_path = s3_path_join(\"s3://\", bucket, f\"{prefix}/data\")\n",
    "dataset_path = download_dir + '/petfinder_for_tutorial'\n",
    "print(f\"Uploading data to {s3_data_path}\")\n",
    "data_uri = S3Uploader.upload(dataset_path, s3_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85a2cf8",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d563be1",
   "metadata": {},
   "source": [
    "Now let’s train the model using the prepared training data.\n",
    "\n",
    "In this example we use local notebook instance to perform local training. If the GPU resources is available for local mode training, the instance_type is set to `local_gpu`. For non-local training, you can set theinstance type to a GPU instance, such as ml.g4dn.xlarge.\n",
    "\n",
    "Note: Depending on how many underlying models are trained, `volume_size` may need to be increased so that they all fit on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c0d085",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type = \"local\"\n",
    "\n",
    "try:\n",
    "    if subprocess.call(\"nvidia-smi\") == 0:\n",
    "        ## Set type to GPU if one is present\n",
    "        instance_type = \"local_gpu\"\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"Instance type = \" + instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8daa45",
   "metadata": {},
   "source": [
    "We will use the prebuilt [autogluon docker container](https://github.com/aws/deep-learning-containers/blob/master/available_images.md#autogluon-training-containers) for the training job. Here we retrieve the prebuilt image using the [image_uris function from the sagemaker python sdk](https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/image_uris.py#L36)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64ac5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = image_uris.retrieve(\n",
    "            \"autogluon\",\n",
    "            region=region,\n",
    "            version=\"0.5.2\",\n",
    "            py_version=\"py38\",\n",
    "            image_scope=\"training\",\n",
    "            instance_type=instance_type,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97590756",
   "metadata": {},
   "source": [
    "**Training script**\n",
    "The `train.py` script provides all the code we need for training a SageMaker model. The training script is very similar to a training script you might run outside of SageMaker, but you can access useful properties about the training environment through various environment variables, such as`SM_MODEL_DIR` which is a string representing the path to the directory to write model artifacts to. These artifacts are uploaded to S3 for model \n",
    "\n",
    "Supposing one input channel, 'training', was used in the call to the estimator's fit() method, the following will be set, following the format `SM_CHANNEL_[channel_name]`. In this example, `SM_CHANNEL_TRAINING` is a string representing the path to the directory containing data in the 'training' channel.\n",
    "\n",
    "For more information about training environment variables, please visit [SageMaker Containers](https://github.com/aws/sagemaker-containers).\n",
    "\n",
    "A typical training script loads data from the input channels, configures training with hyperparameters, trains a model, and saves a model to model_dir so that it can be used later. Hyperparameters are passed to your script as arguments and can be retrieved with an `argparse.ArgumentParser` instance.\n",
    "\n",
    "Because the SageMaker imports the training script, you should put your training code in a main guard (`if __name__=='__main__':`) if you are using the same script to host your model as we do in this example, so that SageMaker does not inadvertently run your training code at the wrong point in execution.\n",
    "\n",
    "For example, the script run by this notebook:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fdea8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mautogluon\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mcore\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mloaders\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m load_zip\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mautogluon\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmultimodal\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m MultiModalPredictor\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker_training\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m environment\n",
      "\n",
      "logger = logging.getLogger(\u001b[31m__name__\u001b[39;49;00m)\n",
      "logger.setLevel(logging.DEBUG)\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mpath_expander\u001b[39;49;00m(path, base_folder):\n",
      "    path_l = path.split(\u001b[33m'\u001b[39;49;00m\u001b[33m;\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[34mreturn\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33m;\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.join([os.path.abspath(os.path.join(base_folder, path)) \u001b[34mfor\u001b[39;49;00m path \u001b[35min\u001b[39;49;00m path_l])\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_train\u001b[39;49;00m(args):\n",
      "\n",
      "    train_data = pd.read_csv(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00margs.data_dir\u001b[33m}\u001b[39;49;00m\u001b[33m/train.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, index_col=\u001b[34m0\u001b[39;49;00m)\n",
      "    \n",
      "    label_col = args.label_col\n",
      "    image_col = args.image_col\n",
      "\n",
      "\n",
      "    train_data[image_col] = train_data[image_col].apply(\u001b[34mlambda\u001b[39;49;00m ele: path_expander(ele, base_folder=args.data_dir))\n",
      "\n",
      "    predictor = MultiModalPredictor(label=label_col)\n",
      "    predictor.fit(\n",
      "        train_data=train_data,\n",
      "        time_limit=\u001b[34m120\u001b[39;49;00m, \u001b[37m# seconds\u001b[39;49;00m\n",
      "        save_path=args.model_dir,\n",
      "    )\n",
      "\n",
      "\n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mSaving the model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    predictor.save(args.model_dir)\n",
      "\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "    parser = argparse.ArgumentParser()\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--data-dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--label-col\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[33m'\u001b[39;49;00m\u001b[33mAdoptionSpeed\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--image-col\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[33m'\u001b[39;49;00m\u001b[33mImages\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \n",
      "    _train(parser.parse_args())\n"
     ]
    }
   ],
   "source": [
    "!pygmentize train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ade44f",
   "metadata": {},
   "source": [
    "In our training script, we use [AutoMM for Multomodal training](https://auto.gluon.ai/dev/tutorials/multimodal/index.html). AutoMM is a deep learning “model zoo” of model zoos. It can automatically build deep learning models that are suitable for multimodal datasets. You will only need to convert the data into the multimodal dataframe format and AutoMM can predict the values of one column conditioned on the features from the other columns including images, text, and tabular data.\n",
    "\n",
    "Under the hood, AutoMM automatically infers the problem type (classification or regression), detects the data modalities, selects the related models from the multimodal model pools, and trains the selected models. If multiple backbones are available, AutoMM appends a late-fusion model (MLP or transformer) on top of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3f63f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifacts_location = f\"s3://{bucket}/{prefix}/artifacts\"\n",
    "hyperparameters = {\n",
    "  'label-col': 'AdoptionSpeed',\n",
    "  'image-col': 'Images'\n",
    "}\n",
    "mm_estimator = Estimator(\n",
    "    entry_point=\"train.py\",\n",
    "    role=role,\n",
    "    output_path=model_artifacts_location,\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    hyperparameters=hyperparameters,\n",
    "    image_uri=image_uri,\n",
    "    volume_size=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc831319",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_estimator.fit({\"training\": data_uri})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ee79fa",
   "metadata": {},
   "source": [
    "## Batch Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1778b58b",
   "metadata": {},
   "source": [
    "Amazon SageMaker Processing allows you to run steps for data pre- or post-processing, feature engineering, data validation, or model evaluation workloads on Amazon SageMaker. Processing jobs accept data from Amazon S3 as input and store data into Amazon S3 as output.\n",
    "\n",
    "![processing](https://sagemaker.readthedocs.io/en/stable/_images/amazon_sagemaker_processing_image1.png)\n",
    "\n",
    "Here, we'll import the test dataset and model artifacts as the input to the processing job. The processing script will perform batch inference using the test dataset against the training model to provide the inference results. The SageMaker Processing job can be used to process terabytes of data in a SageMaker-managed cluster separate from the instance running your notebook server. In a typical SageMaker workflow, notebooks are only used for prototyping and can be run on relatively inexpensive and less powerful instances, while processing, training and model hosting tasks are run on separate, more powerful SageMaker-managed instances.  SageMaker Processing includes off-the-shelf support for Scikit-learn, as well as a Bring Your Own Container option, so it can be used with many different data transformation technologies and tasks.    \n",
    "\n",
    "To use SageMaker Processing, simply supply a Python data preprocessing script as shown below.  For this example, we're using the same Autogluon prebuilt container, which includes the necessary python packages required to process inference on the test data. We use a [`ScriptProcessor`](https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/processing.py#L399) to run your own code within a container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670f7f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_job_name = 'multimodel-inference'\n",
    "mm_processor = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    role=role,\n",
    "    instance_type=\"local\",\n",
    "    instance_count=1, \n",
    "    base_job_name=base_job_name,\n",
    ")\n",
    "processing_job_name = name_from_base(base_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2c6fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifacts_location=mm_estimator.model_data\n",
    "model_artifacts_location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de99b692",
   "metadata": {},
   "source": [
    "The processing script loads the trained model and perform predictions on the test data, as shown below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22bb7461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mautogluon\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mcore\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mloaders\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m load_zip\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mautogluon\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmultimodal\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m MultiModalPredictor\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mglob\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtarfile\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpathlib\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "logger = logging.getLogger()\n",
      "logger.setLevel(logging.INFO)\n",
      "logger.addHandler(logging.StreamHandler())\n",
      "\n",
      "label_col = \u001b[33m'\u001b[39;49;00m\u001b[33mAdoptionSpeed\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "image_col = \u001b[33m'\u001b[39;49;00m\u001b[33mImages\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mparse_args\u001b[39;49;00m() -> \u001b[34mNone\u001b[39;49;00m:\n",
      "    parser = argparse.ArgumentParser()\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--base_dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[33m\"\u001b[39;49;00m\u001b[33m/opt/ml/processing\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    args, _ = parser.parse_known_args()\n",
      "    \u001b[34mreturn\u001b[39;49;00m args\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mload_data\u001b[39;49;00m(file_list: \u001b[36mlist\u001b[39;49;00m):\n",
      "    \u001b[37m# Define columns to use\u001b[39;49;00m\n",
      "    use_cols = []\n",
      "    \u001b[37m# Concat input files\u001b[39;49;00m\n",
      "    dfs = []\n",
      "    \u001b[34mfor\u001b[39;49;00m file \u001b[35min\u001b[39;49;00m file_list:\n",
      "        \u001b[34mif\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(use_cols)==\u001b[34m0\u001b[39;49;00m:\n",
      "            dfs.append(pd.read_csv(file))\n",
      "        \u001b[34melse\u001b[39;49;00m:\n",
      "            dfs.append(pd.read_csv(file, usecols=use_cols))    \n",
      "    \u001b[34mreturn\u001b[39;49;00m pd.concat(dfs, ignore_index=\u001b[34mTrue\u001b[39;49;00m)\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mpath_expander\u001b[39;49;00m(path, base_folder):\n",
      "    path_l = path.split(\u001b[33m'\u001b[39;49;00m\u001b[33m;\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[34mreturn\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33m;\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.join([os.path.abspath(os.path.join(base_folder, path)) \u001b[34mfor\u001b[39;49;00m path \u001b[35min\u001b[39;49;00m path_l])\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmain\u001b[39;49;00m(base_dir: \u001b[36mstr\u001b[39;49;00m, args: argparse.Namespace):\n",
      "    \u001b[37m# Input test files\u001b[39;49;00m\n",
      "    input_dir = os.path.join(base_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33minput/test\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    test_file_list = glob.glob(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00minput_dir\u001b[33m}\u001b[39;49;00m\u001b[33m/*.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mInput file list: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mtest_file_list\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \n",
      "    \u001b[34mif\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(test_file_list) == \u001b[34m0\u001b[39;49;00m:\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mNo input files found in \u001b[39;49;00m\u001b[33m{\u001b[39;49;00minput_dir\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# Input model\u001b[39;49;00m\n",
      "    model_dir = os.path.join(base_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33minput/model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    model_file = glob.glob(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mmodel_dir\u001b[33m}\u001b[39;49;00m\u001b[33m/*.tar.gz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mModel file: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mmodel_file\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[34mif\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m os.path.exists(model_dir):\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mmodel file does not exist\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \n",
      "    model_path = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mmodel_dir\u001b[33m}\u001b[39;49;00m\u001b[33m/model.tar.gz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "    \u001b[34mwith\u001b[39;49;00m tarfile.open(model_path) \u001b[34mas\u001b[39;49;00m tar:\n",
      "        tar.extractall(path=model_dir)\n",
      "    \n",
      "\n",
      "    \u001b[37m# load data into dataframes\u001b[39;49;00m\n",
      "    test_data = load_data(test_file_list)\n",
      "    test_data[image_col] = test_data[image_col].apply(\u001b[34mlambda\u001b[39;49;00m ele: ele.split(\u001b[33m'\u001b[39;49;00m\u001b[33m;\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)[\u001b[34m0\u001b[39;49;00m])\n",
      "    test_data[image_col] = test_data[image_col].apply(\u001b[34mlambda\u001b[39;49;00m ele: path_expander(ele, base_folder=input_dir))\n",
      "    \n",
      "    \u001b[34mfor\u001b[39;49;00m file \u001b[35min\u001b[39;49;00m os.listdir(model_dir):\n",
      "        logger.info(file)\n",
      "    \n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33m ** Loading model from file. **\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    loaded_predictor = MultiModalPredictor.load(model_dir)\n",
      "    predictions = loaded_predictor.predict(test_data.drop(columns=label_col))\n",
      "    \u001b[36mprint\u001b[39;49;00m(predictions[:\u001b[34m5\u001b[39;49;00m])\n",
      "    probas = loaded_predictor.predict_proba(test_data.drop(columns=label_col))\n",
      "    \u001b[36mprint\u001b[39;49;00m(probas[:\u001b[34m5\u001b[39;49;00m])\n",
      "    \n",
      "    \u001b[37m# Write results to local file\u001b[39;49;00m\n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33m ** Writing prediction to file. **\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    predictions.to_json(\u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/processing/output/inference_result/result.json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "\n",
      "    \n",
      "    \n",
      "    \u001b[34mreturn\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33m ** Starting preprocessing. **\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    args = parse_args()\n",
      "    base_dir = args.base_dir\n",
      "    main(base_dir, args)\n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mDone\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n"
     ]
    }
   ],
   "source": [
    "!pygmentize processing_script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0830cdec",
   "metadata": {},
   "source": [
    "We run this script as a processing job. Use the `ScriptProcessor.run()` method. You give the `run()` method one `ProcessingInput` where the source is the test dataset in Amazon S3, one `ProcessingInput` as the CSV file contains the image path, and another `ProcessingInput` to load the trained model from S3. The `destination` is where the script reads this data from, in this case `/opt/ml/processing/input/test` is where the CSV file is downloaded to in the processing container, `/opt/ml/processing/input/test/images` is where the images are stored and `/opt/ml/processing/input/model` is where the model artifact (as a tar.gz file) downloaded to. These local paths inside the processing container must begin with /opt/ml/processing/.\n",
    "\n",
    "Also give the run() method a ProcessingOutput, where the source is the path the script writes output data to. For outputs, the destination defaults to an S3 bucket that the Amazon SageMaker Python SDK creates for you, following the format s3://sagemaker-<region>-<account_id>/<processing_job_name>/output/<output_name/. If you specify the `destination`, the processing job will upload the results, in this case the output is stored in `/opt/ml/processing/output/inference_result` to the output location on S3: `s3://sagemaker-<region>-<account_id>/<processing_job_name>//output/inference_result`. You also give the ProcessingOutputs values for output_name, to make it easier to retrieve these output artifacts after the job is run. \n",
    "\n",
    "The arguments parameter in the run() method are command-line arguments in our preprocessing.py script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9998cc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_processor.run(\n",
    "    code='processing_script.py',\n",
    "    arguments = [\n",
    "                 '--base_dir', '/opt/ml/processing',\n",
    "                ],\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=f\"{data_uri}/test.csv\",\n",
    "            destination=\"/opt/ml/processing/input/test\",\n",
    "            s3_data_distribution_type=\"FullyReplicated\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=f\"{data_uri}/images\",\n",
    "            destination=\"/opt/ml/processing/input/test/images\",\n",
    "            s3_data_distribution_type=\"FullyReplicated\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=model_artifacts_location,\n",
    "            destination=\"/opt/ml/processing/input/model\",\n",
    "            s3_data_distribution_type=\"FullyReplicated\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"inference_result\", source=\"/opt/ml/processing/output/inference_result\", destination=\"inference_result\")\n",
    "    ],\n",
    "    job_name=processing_job_name,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff4b2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_s3_path = f\"s3://{bucket}/{processing_job_name}/output/inference_result\"\n",
    "S3Downloader.download(s3_uri=results_s3_path, local_path='./',sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363ad704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate classification report\n",
    "\n",
    "y_pred_class=pd.read_json('result.json',typ='series')\n",
    "y_test = test_data['AdoptionSpeed']\n",
    "print(metrics.classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85c28d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.concat([test_data, y_pred_class], axis=1)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77417ba0",
   "metadata": {},
   "source": [
    "## Real-time Inference (COMMING SOON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21684961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference_image_uri = image_uris.retrieve(\n",
    "#             \"autogluon\",\n",
    "#             region=region,\n",
    "#             version=\"0.5\",\n",
    "#             py_version=\"py38\",\n",
    "#             image_scope=\"inference\",\n",
    "#             instance_type=\"local\",\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379204cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fc7d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_model_artifacts_location = mm_estimator.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54570427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker import LocalSession\n",
    "\n",
    "# mm_inference_estimator = Model(\n",
    "#     entry_point=\"inference.py\",\n",
    "#     source_dir = \"endpoint_src\",\n",
    "#     role=role,\n",
    "#     model_data=trained_model_artifacts_location,\n",
    "#     image_uri=inference_image_uri,\n",
    "#     sagemaker_session=LocalSession()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0573fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = mm_inference_estimator.deploy(initial_instance_count=1, instance_type=\"local\", endpoint_name=\"mm-ag-model\", wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec85f939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.serializers import NumpySerializer, JSONSerializer\n",
    "from sagemaker import LocalSession\n",
    "\n",
    "\n",
    "#TODO: FIX REAL SERIALIZATION\n",
    "predictor = Predictor(endpoint_name=\"mm-ag-model\",\n",
    "                          sagemaker_session=LocalSession(),\n",
    "                          serializer=sagemaker.serializers.JSONSerializer(),\n",
    "                          deserializer=sagemaker.deserializers.JSONDeserializer()\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dba541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# invocation placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef46974",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108bcddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p37",
   "language": "python",
   "name": "conda_mxnet_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
